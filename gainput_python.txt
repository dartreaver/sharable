import csv
import time
from datetime import datetime, timedelta
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import RunReportRequest
from google.oauth2 import service_account

# Path to your JSON key
credentials = service_account.Credentials.from_service_account_file('/path/to/your-service-account-key.json')

# Create a client with the credentials
client = BetaAnalyticsDataClient(credentials=credentials)

# Function to fetch data with retry logic
def fetch_with_retry(client, request, retries=3, backoff_factor=2):
    for attempt in range(retries):
        try:
            return client.run_report(request=request)
        except Exception as e:
            print(f"Attempt {attempt + 1} failed: {e}")
            if attempt < retries - 1:
                time.sleep(backoff_factor ** attempt)  # Exponential backoff
            else:
                raise

# Prepare headers from metrics and dimensions
headers = [
    "Date", "Host Name", "Page Path", "Unified Screen Class", 
    "Program ID", "Segment ID", "User ID", "Student ID", 
    "Engagement Duration"
]

# Generate the last 90 days of dates
start_date = datetime.now() - timedelta(days=90)
end_date = datetime.now()

# Iterate over each day in the 90-day range
for day in range(90):
    current_date = (start_date + timedelta(days=day)).strftime('%Y-%m-%d')
    
    # Create a unique CSV file for each day
    csv_file_path = f'user_engagement_data_{current_date}.csv'
    
    # Write the data to a pipe-delimited CSV file
    with open(csv_file_path, mode='w', newline='') as file:
        writer = csv.writer(file, delimiter='|')  # Use pipe as the delimiter
        # Write the headers to the CSV
        writer.writerow(headers)
        
        # Initialize offset and limit for pagination
        offset = 0
        limit = 1000
        
        while True:
            # Make an API request to fetch user engagement duration and other dimensions/metrics for the current date
            request = RunReportRequest(
                property="properties/YOUR_PROPERTY_ID",  # Replace with your Google Analytics Property ID
                date_ranges=[{"start_date": current_date, "end_date": current_date}],
                metrics=[{"name": "userEngagementDuration"}],
                dimensions=[
                    {"name": "date"}, {"name": "hostName"}, {"name": "pagePath"}, 
                    {"name": "unifiedScreenClass"}, {"name": "programId"}, 
                    {"name": "segmentId"}, {"name": "customUser:platformUserId"}
                ],
                limit=limit,  # Set the number of rows per request
                offset=offset  # Fetch next set of rows using offset
            )

            # Fetch data using retry logic
            response = fetch_with_retry(client, request)
            
            # Write each row of data in the order defined in the headers
            for row in response.rows:
                # Extract data in the correct order and replace "(not set)" with an empty string
                date = row.dimension_values[0].value if row.dimension_values[0].value != "(not set)" else ""
                host_name = row.dimension_values[1].value if row.dimension_values[1].value != "(not set)" else ""
                page_path = row.dimension_values[2].value if row.dimension_values[2].value != "(not set)" else ""
                unified_screen_class = row.dimension_values[3].value if row.dimension_values[3].value != "(not set)" else ""
                program_id = row.dimension_values[4].value if row.dimension_values[4].value != "(not set)" else ""
                segment_id = row.dimension_values[5].value if row.dimension_values[5].value != "(not set)" else ""
                user_id = row.dimension_values[6].value if row.dimension_values[6].value != "(not set)" else ""
                
                # Placeholder for Student ID as no field for it, will keep it blank
                student_id = ""
                
                engagement_duration = row.metric_values[0].value

                # Write the data to the CSV in the correct order
                writer.writerow([
                    date, host_name, page_path, unified_screen_class, 
                    program_id, segment_id, user_id, student_id, 
                    engagement_duration
                ])

            # If fewer rows are returned than the limit, we've fetched all the data for the day
            if len(response.rows) < limit:
                break

            # Increment the offset for the next request
            offset += limit

    print(f"Data for {current_date} has been written to {csv_file_path}")
